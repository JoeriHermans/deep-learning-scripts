{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adverserial Baysian Optimization\n",
    "\n",
    "Joeri R. Hermans and Gilles Louppe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct 27 20:47:09 CEST 2017\r\n"
     ]
    }
   ],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel, RBF\n",
    "from sklearn.utils import check_random_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_prior_beam_energy(prior):\n",
    "    g = random_gaussian(mu=[30, 60], sigma=1.0)\n",
    "    add_prior(prior, g['mu'], g['sigma'])\n",
    "\n",
    "\n",
    "def add_prior_fermi_constant(prior):\n",
    "    g = random_gaussian(mu=[0, 2], sigma=1.0)\n",
    "    add_prior(prior, g['mu'], g['sigma'])\n",
    "\n",
    "\n",
    "def add_prior(prior, mu, sigma):\n",
    "    prior['mu'].append(mu)\n",
    "    prior['sigma'].append(sigma)\n",
    "\n",
    "\n",
    "def random_gaussian(mu=[-1, 1], sigma=5.0):\n",
    "    return {'mu': np.random.uniform(mu[0], mu[1]),\n",
    "            'sigma': np.random.uniform(0.0, sigma)}\n",
    "\n",
    "\n",
    "def draw_gaussian(d, num_samples, random_state=None):\n",
    "    num_parameters = len(d['mu'])\n",
    "    thetas = torch.zeros((num_samples, num_parameters))\n",
    "    mu = d['mu']\n",
    "    sigma = d['sigma'].exp()\n",
    "    for i in range(0, num_samples):\n",
    "        gaussian = torch.normal(mu, sigma)\n",
    "        thetas[i, :] = gaussian\n",
    "\n",
    "    return thetas\n",
    "\n",
    "\n",
    "def real_experiment(theta, n_samples=100000):\n",
    "    return simulator(theta, n_samples)\n",
    "\n",
    "\n",
    "def simulator(theta, n_samples, random_state=None):\n",
    "    rng = check_random_state(random_state)\n",
    "    samples = simulator_rej_sample_costheta(n_samples, theta, rng)\n",
    "\n",
    "    return torch.from_numpy(samples.reshape(-1, 1)).float()\n",
    "\n",
    "\n",
    "def simulator_rej_sample_costheta(n_samples, theta, rng):\n",
    "    sqrtshalf = theta[0]\n",
    "    gf = theta[1]\n",
    "\n",
    "    ntrials = 0\n",
    "    samples = []\n",
    "    x = torch.linspace(-1, 1, steps=1000)\n",
    "    maxval = torch.max(simulator_diffxsec(x, sqrtshalf, gf))\n",
    "\n",
    "    while len(samples) < n_samples:\n",
    "        ntrials = ntrials + 1\n",
    "        xprop = rng.uniform(-1, 1)\n",
    "        ycut = rng.rand()\n",
    "        yprop = (simulator_diffxsec(xprop, sqrtshalf, gf) / maxval)[0]\n",
    "        if (yprop / maxval) < ycut:\n",
    "            continue\n",
    "        samples.append(xprop)\n",
    "\n",
    "    return np.array(samples)\n",
    "\n",
    "\n",
    "def simulator_diffxsec(costheta, sqrtshalf, gf):\n",
    "    norm = 2. * (1. + 1. / 3.)\n",
    "    return ((1 + costheta ** 2) + simulator_a_fb(sqrtshalf, gf) * costheta) / norm\n",
    "\n",
    "\n",
    "def simulator_a_fb(sqrtshalf, gf):\n",
    "    mz = 90\n",
    "    gf_nom = 0.9\n",
    "    sqrts = sqrtshalf * 2.\n",
    "    x = torch.FloatTensor([(sqrts - mz) / mz * 10])\n",
    "    a_fb_en = torch.tanh(x)\n",
    "    a_fb_gf = gf / gf_nom\n",
    "\n",
    "    return 2 * a_fb_en * a_fb_gf\n",
    "\n",
    "\n",
    "def plot_observations(X_observed, theta, normed=True):\n",
    "    plt.grid(True)\n",
    "    plt.hist(X_observed, histtype=\"bar\", range=(-1, 1), bins=100, normed=normed)\n",
    "    plt.xlim([-1, 1])\n",
    "    if normed:\n",
    "        plt.ylim([0, 2])\n",
    "        plt.ylabel(\"Normalized Number of Events\")\n",
    "    else:\n",
    "        plt.ylim([0, 3000])\n",
    "        plt.ylabel(\"Number of Events\")\n",
    "    plt.title(r\"Distribution of $\\cos(A)$ in $e^-e^+ \\rightarrow \\mu^-\\mu^+$ events.\" + \"\\n\"\n",
    "              r\"$E_{beam}}$ = \" + str(theta[0]) + \"GeV   -   \" + r\"$G_f$ = \" + str(theta[1]))\n",
    "    plt.xlabel(r\"$\\cos(A)$\")\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def sample_real_data(p_r, batch_size=256):\n",
    "    samples = torch.zeros((batch_size, 1))\n",
    "    num_samples_p_r = len(p_r)\n",
    "    for index in range(0, batch_size):\n",
    "        random_index = random.randint(0, num_samples_p_r - 1)\n",
    "        samples[index, :] = p_r[random_index]\n",
    "\n",
    "    return torch.autograd.Variable(samples)\n",
    "\n",
    "\n",
    "def sample_generated_data(proposal, batch_size=256):\n",
    "    # Sample `batch_size` thetas according to our proposal distribution.\n",
    "    thetas = draw_gaussian(proposal, batch_size)\n",
    "    # Obtain the individual Gaussians.\n",
    "    theta_beam_energy = thetas[:, 0]\n",
    "    theta_fermi_constant = thetas[:, 1]\n",
    "    # Sample according to the proposal distribution.\n",
    "    samples = torch.zeros((batch_size, 1))\n",
    "    for sample_index, theta in enumerate(thetas):\n",
    "        samples[sample_index, :] = simulator(theta, 1)\n",
    "\n",
    "    return torch.autograd.Variable(samples)\n",
    "    \n",
    "    \n",
    "def compute_gradient_penalty(critic, real, fake, l=5.0):\n",
    "    # Compute x_hat and its output.\n",
    "    epsilon = torch.rand(real.size())\n",
    "    x_hat = epsilon * real + ((1. - epsilon) * fake)\n",
    "    x_hat = torch.autograd.Variable(x_hat, requires_grad=True)\n",
    "    y_hat = critic(x_hat)\n",
    "    # Compute the associated gradients.\n",
    "    gradients = torch.autograd.grad(outputs=y_hat, inputs=x_hat,\n",
    "                                    grad_outputs=torch.ones(y_hat.size()),\n",
    "                                    create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    # Prevent norm 0 causing NaN.\n",
    "    gradients = gradients + 1e-16\n",
    "    # Compute the gradient penalty.\n",
    "    gradient_penalty = l * ((gradients.norm(2, dim=1) - 1.) ** 2)\n",
    "\n",
    "    return gradient_penalty\n",
    "    \n",
    "\n",
    "class Critic(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_hidden):\n",
    "        super(Critic, self).__init__()\n",
    "        self.fc_1 = torch.nn.Linear(1, num_hidden)\n",
    "        self.fc_2 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.fc_3 = torch.nn.Linear(num_hidden, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc_1(x))\n",
    "        x = F.relu(self.fc_2(x))\n",
    "        x = (self.fc_3(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class CriticWithSigmoid(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_hidden):\n",
    "        super(CriticWithSigmoid, self).__init__()\n",
    "        self.fc_1 = torch.nn.Linear(1, num_hidden)\n",
    "        self.fc_2 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.fc_3 = torch.nn.Linear(num_hidden, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc_1(x))\n",
    "        x = F.relu(self.fc_2(x))\n",
    "        x = F.sigmoid(self.fc_3(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEvCAYAAACAFCxvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEhF+FwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f823e5e8b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of true experimental observations: 100000\n"
     ]
    }
   ],
   "source": [
    "# Define the true parameterization of theta.\n",
    "theta_true = [45., .9]\n",
    "\n",
    "# This parameterization will produce the following distribution in the real experiment.\n",
    "real_data = real_experiment(theta_true).view(-1).numpy()\n",
    "plot_observations(real_data, theta_true)\n",
    "\n",
    "# Display the total number of observations available.\n",
    "num_real_samples = len(real_data)\n",
    "print(\"Total number of true experimental observations: \" + str(num_real_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "In order to find the parameterizations which fit the true experimental observation, we want to pick the parameterization of a theory which maximizes the loss of our critic after being optimally trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize the proposal distribution.\n",
    "proposal = {\n",
    "    'mu': [41., .7],   # Mean of the proposal distribution.\n",
    "    'sigma': [1., 1.]  # Uncertainty of the proposal distribution.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "copy from numpy.float32 to torch.FloatTensor isn't implemented",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-68fb344fae3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproposal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-54cc61cbeb1e>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(proposal, experiment_data, max_iterations, batch_size)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# Fit the critic optimally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_critic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproposal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Add the loss to the Gaussian Process, and fit the proposal distribution optimally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mfit_proposal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproposal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-54cc61cbeb1e>\u001b[0m in \u001b[0;36mfit_critic\u001b[0;34m(proposal, p_r, critic, optimizer, num_critic_iterations, batch_size)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit_critic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproposal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_critic_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m      \u001b[0;31m# Fetch the data batches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mx_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_real_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mx_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_generated_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproposal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Fit the critic optimally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-784281dff1c7>\u001b[0m in \u001b[0;36msample_real_data\u001b[0;34m(p_r, batch_size)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mrandom_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples_p_r\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_r\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: copy from numpy.float32 to torch.FloatTensor isn't implemented"
     ]
    }
   ],
   "source": [
    "fit(proposal, real_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit(proposal, experiment_data, max_iterations=100, batch_size=256):\n",
    "    # Define the critic network with 100 hidden neurons.\n",
    "    critic = CriticWithSigmoid(100)\n",
    "    # Define the global optimizer of the critic.\n",
    "    critic_optimizer = torch.optim.Adam(critic.parameters(), lr=0.001)\n",
    "    # Seed the gaussian process.\n",
    "    # Apply the fitting process for a maximum number of 100 iterations.\n",
    "    for iteration in range(0, max_iterations):\n",
    "        # Fit the critic optimally.\n",
    "        loss = fit_critic(proposal, experiment_data, critic, critic_optimizer, 10000, batch_size)\n",
    "        # Add the loss to the Gaussian Process, and fit the proposal distribution optimally.\n",
    "        fit_proposal(proposal)\n",
    "        # Display the current proposal distribution.\n",
    "        print(\"Current Proposal Distribution:\")\n",
    "        print(\"  mu: \" + str(proposal['mu']))\n",
    "        print(\"  sigma: \" + str(proposal['sigma']))\n",
    "\n",
    "        \n",
    "def fit_proposal(proposal):\n",
    "    pass\n",
    "        \n",
    "        \n",
    "def fit_critic(proposal, p_r, critic, optimizer, num_critic_iterations=50000, batch_size=256):\n",
    "     # Fetch the data batches.\n",
    "    x_r = sample_real_data(p_r, batch_size)\n",
    "    x_g = sample_generated_data(proposal, batch_size)\n",
    "    # Fit the critic optimally.\n",
    "    for iteration in range(0, num_critic_iterations):\n",
    "        # Reset the gradients.\n",
    "        critic.zero_grad()\n",
    "        # Forward pass with real data.\n",
    "        y_r = critic(x_r).mean()\n",
    "        # Forward pass with generated data.\n",
    "        y_g = critic(x_g).mean()\n",
    "        # Obtain gradient penalty (GP).\n",
    "        gp = compute_gradient_penalty(critic, x_r.data, x_g.data).mean()\n",
    "        # Compute the loss, and the accompanying gradients.\n",
    "        loss = y_g - y_r + gp\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return loss.data.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
